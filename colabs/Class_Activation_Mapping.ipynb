{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WkkXLGBrycfx"
      },
      "outputs": [],
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdR-yrNv9Fgk"
      },
      "source": [
        "# ProteInfer Class Activation Mapping (CAM)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqbcum1HM8aL"
      },
      "source": [
        "\n",
        "## Initial setup (code/data download)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting seaborn\n",
            "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
            "     |████████████████████████████████| 292 kB 8.5 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.3.4)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.5.4)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.16.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (3.1.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.8.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.12.0)\n",
            "Installing collected packages: seaborn\n",
            "Successfully installed seaborn-0.11.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbK8U6SEKqUU",
        "outputId": "b41adc0f-c74e-4a26-fd34-93ad42ee4989"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "from proteinfer import inference, parenthood_lib, baseline_utils, utils, colab_evaluation\n",
        "\n",
        "import subprocess\n",
        "import shlex\n",
        "import tqdm \n",
        "import sklearn\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "\n",
        "from plotnine import ggplot, geom_point, geom_point, geom_line, aes, stat_smooth, facet_wrap, xlim,coord_cartesian,theme_bw,labs,ggsave\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "T7OLyg9DF3uw"
      },
      "outputs": [],
      "source": [
        "!wget -qN https://storage.googleapis.com/brain-genomics-public/research/proteins/proteinfer/models/zipped_models/noxpnd_cnn_swissprot_ec_random_swiss-cnn_for_swissprot_ec_random-13685140.tar.gz\n",
        "!tar xzf noxpnd_cnn_swissprot_ec_random_swiss-cnn_for_swissprot_ec_random-13685140.tar.gz\n",
        "!wget -qN https://storage.googleapis.com/brain-genomics-public/research/proteins/proteinfer/colab_support/parenthood.json.gz\n",
        "!wget -qN https://storage.googleapis.com/brain-genomics-public/research/proteins/proteinfer/blast_baseline/fasta_files/SWISSPROT_RANDOM_EC/eval_test.fasta\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ERnBaCG_O00k"
      },
      "outputs": [],
      "source": [
        "def get_ec_num_mapping():\n",
        "  tree = ET.parse('enzyme-data.xml')\n",
        "  root = tree.getroot()\n",
        "  rows = root[0][3].findall('row')\n",
        "  rows = root.findall(\".//field[@name='accepted_name']..\")\n",
        "  ec_nums = {}\n",
        "  for row in rows:\n",
        "      ec_num = row.find(\".//*[@name='ec_num']\").text\n",
        "      name = row.find(\".//*[@name='accepted_name']\").text\n",
        "      try:\n",
        "        ec_nums[ec_num]=name\n",
        "      except TypeError:\n",
        "        continue\n",
        "  return ec_nums\n",
        "\n",
        "def download_dataset():\n",
        "  total = 13\n",
        "  file_shard_names = ['https://storage.googleapis.com/brain-genomics-public/research/proteins/proteinfer/datasets/swissprot/random/test-{:05d}-of-{:05d}.tfrecord'.format(i,total) for i in range(total)]\n",
        "\n",
        "  for shard_name in tqdm.tqdm(file_shard_names, position=0,desc=\"Downloading\"):\n",
        "    subprocess.check_output(shlex.split(f'wget {shard_name}'))\n",
        "  return "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrEsBu1CA7Ut",
        "outputId": "c4117fd4-ff22-4e67-cde9-55e7ddc20721"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100%|██████████| 13/13 [00:07<00:00,  1.74it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.dpi'] = 100\n",
        "!wget -qN https://www.enzyme-database.org/downloads/enzyme-data.xml.gz\n",
        "!gunzip -f enzyme-data.xml.gz\n",
        "\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "ec_nums = get_ec_num_mapping()\n",
        "download_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWu0UovMMzEC"
      },
      "source": [
        "##Read in the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from proteinfer import protein_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'proteinfer.protein_dataset' from '/app/proteinfer/protein_dataset.py'>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "protein_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlyjYvhL9W8t",
        "outputId": "4db10071-5e40-41c9-bea3-2b2a7167ceaa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]WARNING: Logging before flag parsing goes to stderr.\n",
            "W0419 22:28:08.482895 140425461663552 deprecation.py:323] From /app/proteinfer/protein_dataset.py:293: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "54285it [00:26, 2061.59it/s]\n"
          ]
        }
      ],
      "source": [
        "sequence_iterator = protein_dataset.yield_examples(\"./test*.tfrecord\")\n",
        "sequences = []\n",
        "labels = []\n",
        "ids = []\n",
        "for example in tqdm.tqdm(sequence_iterator):\n",
        "  ids.append(example[protein_dataset.SEQUENCE_ID_KEY])\n",
        "  sequences.append(example[protein_dataset.SEQUENCE_KEY])\n",
        "  labels.append(example[protein_dataset.LABEL_KEY])\n",
        "\n",
        "# If we want to optimise for inference speed we should sort the dataset by\n",
        "# sequence length:\n",
        "seq_lengths = [len(x) for x in sequences]\n",
        "indices = np.argsort(-np.array(seq_lengths)).tolist()\n",
        "\n",
        "ids = [ids[indices[x]] for x in range(len(indices))]\n",
        "sequences = [sequences[indices[x]] for x in range(len(indices))]\n",
        "labels = [set(labels[indices[x]]) for x in range(len(indices))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pScRsRCwX2H"
      },
      "source": [
        "## Load the saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zljPgF2BMBj-",
        "outputId": "7cc5050c-877f-4bf0-91a2-d6638a2f4997"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0419 22:30:36.525437 140425461663552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/ragged/ragged_tensor.py:1586: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ],
      "source": [
        "inferrer = inference.Inferrer(\n",
        "    'noxpnd_cnn_swissprot_ec_random_swiss-cnn_for_swissprot_ec_random-13685140',use_tqdm= True, batch_size=32,activation_type=\"representation\"\n",
        ")\n",
        "\n",
        "label_vocab = list(inferrer.get_variable('label_vocab:0').astype(str))\n",
        "label_normalizer = parenthood_lib.get_applicable_label_dict(\n",
        "    'parenthood.json.gz')\n",
        "\n",
        "\n",
        "kernel = inferrer.get_variable(\"logits/kernel/read:0\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EoIhtq-6f69y"
      },
      "outputs": [],
      "source": [
        "def get_multi_full_ec(labels, desired_number=3):\n",
        "  subset = [x for x in labels if x.startswith(b\"EC:\")]\n",
        "  subset = [x for x in subset if b'-' not in x]\n",
        "  if len(subset)==desired_number:\n",
        "    return subset\n",
        "  else:\n",
        "    return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "W9h1rwNQk2yE"
      },
      "outputs": [],
      "source": [
        "def moving_average(a, n=3) :\n",
        "    new = np.zeros_like(a)\n",
        "    length_dim = a.shape[0]\n",
        "    for i in range(length_dim):\n",
        "      new[i,:]=np.mean(a[np.maximum(i-n,0):np.minimum(i+n,length_dim),:],axis=0)\n",
        "    return new\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yxJF7xQYG13_"
      },
      "outputs": [],
      "source": [
        "from matplotlib import colors as clr\n",
        "from matplotlib import pyplot as plt\n",
        "palette = clr.LinearSegmentedColormap.from_list('custom blue', ['#FFFFFF','#EEEEEE','#00EE00'], N=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pFaTvOjAR0Il"
      },
      "outputs": [],
      "source": [
        "items_that_satisfy_criteria = []\n",
        "for i in range(len(sequences)):\n",
        "  new_lab = get_multi_full_ec(labels[i],desired_number=2)\n",
        "  new_seq = sequences[i]\n",
        "  new_id = ids[i]\n",
        "  if len(new_lab)>0:\n",
        "    items_that_satisfy_criteria.append({'labels':new_lab, 'sequence':new_seq, 'id':new_id})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhGd6pdzodrP"
      },
      "source": [
        "## Perform inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0G1Njx6VyF58",
        "outputId": "4d507d58-7cc7-43ba-8c54-41b21fc14e1c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Annotating batches of sequences:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Annotating batches of sequences: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "representation: (1,)\n",
            "kernel: (1100, 5134)\n",
            "label_ids: 2\n",
            "               \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "matmul: Input operand 0 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-2aafb4a5ce6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                \"\"\")\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mcontributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0msum_contributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 0 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)"
          ]
        }
      ],
      "source": [
        "counter = 0\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.set(rc={'figure.figsize': (15, 35)})\n",
        "\n",
        "one_by_one = False\n",
        "ids = ['Q4LB35', 'Q54QE4', 'P54889', 'Q9PLG1', 'O94632', 'P19835', 'Q3MEJ8']\n",
        "if True:\n",
        "    sns.set(rc={'figure.figsize': (15, 2)})\n",
        "\n",
        "for item in items_that_satisfy_criteria:\n",
        "    if item['id'].decode() in ids or one_by_one:\n",
        "\n",
        "        the_labels = item['labels']\n",
        "        representation = inferrer.get_activations(\n",
        "            [item['sequence'].decode(\"utf-8\")])\n",
        "        label_ids = [label_vocab.index(x.decode('utf-8')) for x in the_labels]\n",
        "        print(f\"\"\"\n",
        "representation: {representation.shape}\n",
        "kernel: {kernel.shape}\n",
        "label_ids: {len(label_ids)}\n",
        "               \"\"\")\n",
        "        contributions = np.matmul(representation.squeeze(), kernel)[:, label_ids]\n",
        "\n",
        "        sum_contributions = contributions.sum(axis=1)\n",
        "        contributions = np.maximum(contributions, 0)\n",
        "        contributions = moving_average(contributions, 80)\n",
        "        contributions = contributions / contributions.max(axis=0,\n",
        "                                                          keepdims=True)\n",
        "\n",
        "        df = pd.DataFrame(contributions.T)\n",
        "        try:\n",
        "            df.index = [\n",
        "                ec_nums[x.decode().replace(\"EC:\", \"\")].replace(\n",
        "                    \"<em>\",\n",
        "                    \"\").replace(\"</em>\",\n",
        "                                \"\").replace(\"<small>\",\n",
        "                                            \"\").replace(\"</small>\", \"\")\n",
        "                for x in the_labels\n",
        "            ]\n",
        "        except KeyError:\n",
        "            continue\n",
        "        print(item['id'].decode())\n",
        "        ax = None\n",
        "        if False:\n",
        "            ax = axes[counter]\n",
        "        try:\n",
        "            g = sns.heatmap(df, cmap=palette, xticklabels=500, ax=ax, vmin=0)\n",
        "            counter += 1\n",
        "            g.set_title(item['id'].decode())\n",
        "            for _, spine in g.spines.items():\n",
        "                spine.set_visible(True)\n",
        "            plt.yticks(rotation=0)\n",
        "            plt.xticks(rotation=0)\n",
        "            plt.subplots_adjust(hspace=0.7)\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "        if True:\n",
        "            plt.show()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Proteinfer CAM v3",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
